      <emu-clause id="StructuredData.SharedArrayBuffer.abstract.MemoryLock" aoid="MemoryLock">
	<h1>MemoryLock( sab, offset, size )</h1>

	<P> FIXME: This may not adequately specify global synchronization. It may be an error to attempt to operationalize this.  But it's important to specify that overlapping but non-indentical atomic accesses to the same locations may actually be racy. </p>

	<emu-alg>
	  1. Assert: _sab_ is a SharedArrayBuffer
	  1. Assert: _offset_ &ge; 0 and _offset_ + _size_ &le; _sab_.byteLength and _offset_ mod _size_ == 0
	  1. Assert: _size_ is 1, 2, or 4.
	  1. Assert: The calling agent's rights are cleared.
	  1. Let _G_ be the unique identifier for the memory of _sab_
	  1. Wait until no other agent's access rights specify the triple (_G_, _offset_, _size_), then set the calling agent's rights to (_G_, _offset_, _size_)
	</emu-alg>

	<emu-note>
	  <p> MemoryLock communicates with other agents. </p>
	</emu-note>

	<emu-note>
	  <p> Atomicity is only guaranteed for same-sized accesses to the same memory locations, hence the attempt above at operationalizing that.  But that may be a mistake. </p>
	</emu-note>

      </emu-clause>

      <emu-clause id="StructuredData.SharedArrayBuffer.abstract.MemoryUnlock" aoid="MemoryUnlock">
	<h1>MemoryUnlock()</h1>
	<emu-alg>
	  1. Assert: The calling agent's rights are not cleared.
	  1. FIXME: Somehow specify that all local writes will be observed by other agents before they observe that the flag is ~false~.
	  1. Clear the calling agent's rights
	</emu-alg>
	<emu-note>
	  <p> MemoryUnlock communicates with other agents. </p>
	</emu-note>
      </emu-clause>


<emu-clause id="ObjectBehaviors">
  <h1>Ordinary and Exotic Object Behaviors (ES6 9)</h1>
  <emu-clause id="ObjectBehaviors.Exotic">
    <h1>Built-in Exotic Object Internal Methods and Slots (ES6 9.4)</h1>
    <emu-clause id="ObjectBehaviors.Exotic.IntegerIndexed">
      <h1>Integer Indexed Exotic Objects (ES6 9.4.5)</h1>
      <P> FIXME: It's possible that the shared-memory case should be embedded in GetValueFromBuffer and SetValueInBuffer, since the latter have callers elsewhere. </p>
      <emu-clause id="ObjectBehaviors.Exotic.IntegerIndexed.ElementGet">
        <h1>IntegerIndexedElementGet ( O, index ) (ES6 9.4.5.8)</h1>
        <p>Replace 14 with the following algorithm:</p>
        <emu-alg>
          1. If IsSharedMemory(_buffer_) is true, then:
            1. Return GetValueFromSharedBuffer( _buffer_, _indexedPosition_, _elementType_ )
          1. Else
            1. Return GetValueFromBuffer( _buffer_, _indexedPosition_, _elementType_ )
        </emu-alg>
      </emu-clause>

      <emu-clause id="ObjectBehaviors.Exotic.IntegerIndexed.ElementSet">
        <h1>IntegerIndexedElementSet ( O, index, value ) (ES6 9.4.5.9)</h1>
        <p>Replace step 16 with the following algorithm:</p>
        <emu-alg>
          1. If IsSharedMemory(_buffer_) is true, then
            1. Perform SetValueInSharedBuffer( _buffer_, _indexedPosition_, _elementType_, _numValue_ )
          1. Else:
            1. Perform SetValueInBuffer( _buffer_, _indexedPosition_, _elementType_, _numValue_ )
        </emu-alg>
      </emu-clause>
    </emu-clause>
  </emu-clause>
</emu-clause>
          
      <emu-clause id="StructuredData.SharedArrayBuffer.abstract.GetValueFromSharedBuffer" aoid="GetValueFromSharedBuffer">
        <h1>GetValueFromSharedBuffer ( arrayBuffer, byteIndex, type )</h1>
        <P> This is the same as ArrayBuffer's GetValueFromBuffer (ES6 24.1.1.5) except that: </p>
        <ul>
          <li> The _arrayBuffer_ parameter is a SharedArrayBuffer
          <li> There is no _isLittleEndian_ parameter, it is "not present". The implementation must determine the same value for _isLittleEndian_ in all agents that can communicate through shared memory (see Atomics.isLockFree for more precise wording, for now)
          <li> There is no detachment check (step 1)
          <li> Use the [[SharedArrayBufferData]] internal slot (step 4)
        </ul>
      </emu-clause>
      
      <emu-clause id="StructuredData.SharedArrayBuffer.abstract.SetValueInSharedBuffer" aoid="SetValueInSharedBuffer">
        <h1>SetValueInSharedBuffer ( arrayBuffer, byteIndex, type, value )</h1>
        <P> This is the same as ArrayBuffer's SetValueInBuffer (ES6 24.1.1.6) except that: </p>
        <ul>
          <li> The _arrayBuffer_ parameter is a SharedArrayBuffer
          <li> There is no _isLittleEndian_ parameter, it is "not present".
          <li> There is no detachment check (step 1)
          <li> Use the [[SharedArrayBufferData]] internal slot (step 5)
        </ul>
      </emu-clause>




        
        A step in the algorithms below that is marked "With atomic access to ..." is known as an atomic step.  There must be a single total order (shared by all the agents that are able to communicate through shared memory) in which atomic steps occur, known as the atomics order.  If an atomic step R reads some bytes B<sub>0</sub> through B<sub>n</sub> in a SharedArrayBuffer, for each byte B it may return any of:</p>

      <p> There is a relation <em>happens-before</em> on program steps that is defined as follows. </p>
      <ul>
        <li> If a step S precedes a step T in the dynamic semantics of a program within a single agent then S happens-before T.
        <li> If a step S writes a value with an atomic operation synchronizes-with a step T then S happens-before T
        <li> There are certain inter-agent, embedding-specific operations that contribute to the happens-before relationship; see the later section on Web Browser embedding.
      </ul>


      Note, how do the futex sections figure into all of this?


      <p> A step in the algorithms below that is marked "With atomic access to ..." is known as an atomic step.  There must be a single total order (shared by all the agents that are able to communicate through shared memory) in which atomic steps occur, known as the atomics order.  If an atomic step R reads some bytes B<sub>0</sub> through B<sub>n</sub> in a SharedArrayBuffer, for each byte B it may return any of:</p>
      <ul>
        <li> The most recent (in the atomics order) value written by an atomic step to B.
        <li> If a non-atomic step S wrote to B, and S happens-before R and there is no other step T that writes to B such that S happens-before T and T happens-before R, then the value that S wrote to B.
        <li> If a non-atomic step U wrote to B and neither U happens-before R nor R happens-before U, then the value U wrote to B.
      </ul>

      <p>Notes:</p>
      <ul>
        <li> Data-race free programs are sequentially consistent.
        <li> The fact that all Atomics accesses occur through SharedTypedArrays instead of SharedDataViews or directly to the SharedArrayBuffer guarantees that accesses will be aligned.
        <li> If two atomic steps access the same elements of a SharedArrayBuffer through SharedTypedArrays with different element sizes, they do not induce a happens-before edge, but they do still occur in the global atomics order.
        <li> Atomic steps do not have to be through the same type SharedTypedArray to induce a happens-before edge.
      </ul>
      
      <p> If the two threads access the same shared memory cells , and at least one access is not an atomic operation
      <p> Atomic accesses to memory are totally ordered. </p>


      <!--
      <p> In the algorithms below, the algorithm step 'With atomic access to (_buffer_, _indexedPosition_, _elementSize_)' means the following:</p>
      <ul>
        <li> If several agents are claiming atomic access to exactly the same _elementSize_ memory cells then these atomic sections are serialized, each agent executes all its dependent steps while the other agents are waiting
        <li> FIXME: Well-defined atomic sections are globally ordered
        <li> FIXME: It's possible to create ill-defined behavior with overlapping
        <li> FIXME: Conflicts are implementation dependent and can change over time (eg, moving from a spinlock to an atomic can change behavior)
      </ul>
-->

    <emu-clause id="Atomics.loadUnordered">
      <h1>Atomics.loadUnordered( typedArray, index )</h1>
      <emu-note>
        <p> This is the same operation as Atomics.load, but where the observable memory effects of Atomics.load relative to operations before and after it are defined, Atomics.loadUnordered can be rearranged (in terms of memory effects) with unordered operations that precede or succeed it, including non-atomic operations.  Atomics.loadUnordered can be implemented much more efficiently than Atomics.load on almost all platforms. </p>
      </emu-note>
    </emu-clause>
    
    <emu-clause id="Atomics.storeUnordered">
      <h1>Atomics.storeUnordered( typedArray, index, value )</h1>
      <emu-note>
        <p> This is the same operation as Atomics.store, but where the observable memory effects of Atomics.store relative to operations before and after it are defined, Atomics.storeUnordered can be rearranged (in terms of memory effects) with unordered operations that precede or succeed it, including non-atomic operations.  Atomics.storeUnordered can be implemented much more efficiently than Atomics.store on almost all platforms. </p>
      </emu-note>
    </emu-clause>

      


        <ol>
          <li> Two candidate atomic writes that interact with memory at the same
            time (ie one write attempts to start before the other is finished) must
            either write to the same byte range or must write to disjoint byte
            ranges.

          <li> A candidate atomic read only reads the value written by a viable
            candidate atomic write to the same bytes that the read reads from.
        </ol>
          
        <p>The reason for the first rule is that non-lock-free and lock-free atomics are implemented differently and the former is not atomic on the hardware in the same sense as the latter.  Suppose an eight-byte non-lock-free candidate atomic write E attempts to interact with the memory system at the same time as a four-byte lock-free candidate atomic write F.  (We don't have eight-byte atomics at present but we may have them in the future, and there are 32-bit platforms, such as MIPS, that do not support 64-bit atomics.)  E acquires a lock, then writes the data bytes in some arbitrary order, then releases the lock.  While E holds the lock, F interacts directly with the memory system to write its four bytes as a unit.  The result may easily be that some of the bytes written for E are written before the four bytes of F, and some after.  As a result, the bytes in memory at the location of F may be a jumble of the two values, contrary to the desire that atomics execute in a total order.</p>

        <p>The reason for the second rule is that it is possible to perform candidate data writes (and non-viable candidate atomic writes) to the same locations that we perform candidate atomic reads to.  Such writes are not properly ordered with the candidate atomic reads -- in the case of candidate data writes this is obvious, in the case of candidate atomic writes the same argument about lock-free and non-lock-free atomics as for the first rule can be adapted -- and do not give rise to reliable synchronization.</p>

        <p>("Ordering" is the correct explanation above but is sort of nebulous.  Can we do better?)</p>

        <p>We want to reserve the notion of a "data race" for the conventional higher-level concept below, so what we do with viability is to create a dynamic type system that (in the semantics, though not in the implementation) checks that candidate atomic writes do not interfere and that candidate atomic reads only read from compatible candidate atomic writes.  From this we get the synchronization order, as desired.</p>

        <p>Operationally, viability can be established through two mechanism, a reservation system for atomic accesses and a tagging system for memory contents.  These are specification mechanisms: they are not intended to be implemented.  They simply allow us to separate synchronizing events from non-synchronizing events.</p>

        <p>The tagging scheme associates a triplet (Kind,N,J) with each byte where Kind is Atomic, Regular or Init, N is a byte count, and J is a number between 0 and N-1 inclusive.  The tag (Atomic,4,1) means that the byte was written as part of an atomic write of width 4, and this is byte 1 (ie the second byte). The tag (Regular,0,0) means the byte was written by a regular write (of some unknown width). The tag (Init,0,0) means the byte was written by a special initializing write (of some unknown width).</p>
          
        <p>A candidate atomic write to a sequence of locations i..j creates a reservation for i..j; if a reservation for i..j exists it waits until that reservation has been cleared.  It then writes the data bytes with the tags (Atomic,j-i+1,k) where k is 0, 1, up to j-i+1, and finally clears the reservation.  If the reservation was already cleared by another instruction then the candidate atomic write is not viable.</p>

        FIXME: What about the total order?  Is that a side condition?  (Probably best, but if so worth a note here.)  Above we only have a partial order.

        <p>A data write to a sequence of locations i..j clears any reservation for i..j and writes the data bytes with tags (Regular,0,0).</p>

        <p>An initializing write to a sequence of locations i..j clears any reservation for i..j and writes the data bytes with tags (Init,0,0).  Initializing writes are performed by the constructor of the SharedArrayBuffer, and may be performed by mechanisms outside this proposal.</p>

        <emu-note>
          <p>In the case of translation from C/C++, program semantics may require fresh objects to be read by atomic reads without first being initialized by atomic writes.  Initializing writes add a complication, because we're creating an "as-if" situation where the semantics say that if your program blessed a memory area as newly-initialized by some unspecified means then an atomic read from the area is viable. </p>
        </emu-note>
            
        <p>A candidate atomic read to a sequence of locations i..j waits until there is no longer any reservation for i..j then reads the locations.  If the tags of the locations are not of the form (Atomic,j-i+1,k) for k in the sequence 0, 1, j-i+1, or all of the form (Init,0,0), then the read is not viable.</p>

        <p><b>FIXME:</b> Viability can be made more flexible by allowing an atomic read to read the non-atomic write of the same thread.</p>

        <p>A candidate atomic write (including the write operation of a read-modify-write) W is <em>viable</em> in some execution of an agent cluster if it does not interfere with another candidate atomic write V, where:</p>
        <ol>
          <li> W and V access overlapping but non-identical sequences of bytes in the shared memory
        </ol>

        <p>A candidate atomic read (including the read operation of a read-modify-write) R is <em>viable</em> in some execution of an agent cluster if it sees the value written by a viable candidate atomic write W, where:</p>
        <ol>
          <li> W and R access the same sequence of bytes in the shared memory, and
          <li> R does not see a value for any of those bytes written by some other write V
        </ol>


        <emu-note>
          <p> ... can be used to model an implementation where we have lock-free and non-lock-free atomic operations, where atomic operations execute atomically and in a total order only if they do not conflict in the execution with atomic operations that overlap but do not match the access range or with non-atomic operations.</p>

          <p>It may be possible to use these to more formally specify all races, so that those can be put on a firmer footing; doing so would mean BeginAtomic, BeginNonAtomic, and EndAtomic would need to remove values from the non-atomic transaction set when found to conflict.</p>
        </emu-note>

	


<!--
    Clippings.  Not sure how everything fits in.

        <li>If two candidate atomic operations do not conflict then they are both viable.
        <li>If two candidate atomic operations match and conflict  then they are executed one after the other, and both are viable.
          <li>
        <li>If two atomic operations overlap but do not conflict then both are viable.  NOTE: this is a problem in some sense if the first is a write and the second is a read, because the read will read from some memory that was written by something other than an atomic operation.  This is why we have tagging.  So here we see that we don't need tagging for (simple) viability but we need tagging for synchronizes-with.
        <li>If a non-atomic read overlaps and conflicts with an atomic operation then the atomic operation is viable.  NOTE: The normal definition of a race is that two operations conflict and at least one of them is a write, so it's arguable that the atomic operation should be not viable here.
        <li>(Something about operations that cover others, notably with three operations.)
      </ul>
-->

	

      <!--
      <p>The <em>atomic accesses</em> of an execution are those atomic memory operations that are viable in that execution; the <em>data accesses</em> are all the other memory operations.</p>

      We need to pin down what reordering can do because compilers do reordering above and beyond what the hardware will do with speculation and write buffering, and data races will expose these reorderings as well as the reorderings done by the hardware.

      We need to pin down what the synchronizing events are in order to see the complete total order of atomic operations, including non-access events.  Non-access events can and probably should be modeled in terms of accesses: when an event pair creates a synchronizes-with edge, it is as if the source is a write to a hidden shared location just(?) before the call to the source operation returns and the sink is a read from that location just(!) before the sink operation returns.
      -->


            <!-- From ReadSharedMemory
      , provided such speculation does not violate
        transformation rules described earlier (notably rules about
        reordering with respect to synchronizing events) -->

      <!-- From WriteSharedMemory
           provided such delay does not violate transformation rules
           described earlier (notably rules about reordering with
           respect to synchronizing events). -->


      <p>[Semi-obsolete prose] If an atomic access is not in a data race, then the shared memory reads and writes issued by the atomic access shall be performed indivisibly (while also following the rules of ReadSharedMemory and WriteSharedMemory), and in a read-modify-write atomic access no write by another agent shall be allowed to execute between the read and the write.</p>

      <p>[Probably obsolete now] <b>FIXME:</b> operationalize an atomic read "seeing" an atomic write.  This need not be hard.  Viable atomic read R sees viable atomic write W if W is before R in the total order, the access ranges of R and W overlap, and there are no other writes between W and R that scribble on all the bytes read by R.  This would be a lot cleaner with a restriction as introduced by tagging, since without tagging you can have the situation that a single read R sees multiple atomic writes if those writes wrote to different parts of the datum accessed by R.</p>


              <p><b>FIXME:</b> Why only a read-modify-write access next?</p>

        <p>When an atomic read-modify-write access is in a data race, then
          those accesses are
          performed as if the qualifier "With atomic access to shared
          memory" were omitted from the algorithms below.</p>

        <emu-note>
          <p>[Semi-obsolete prose] Hence, a write access from another agent may be allowed
            to execute between the read and the write of the pair,
            and, as defined by ReadSharedMemory and
            WriteSharedMemory, even the individual accesses in the
            atomic access may not be executed atomically.</p>

          <p>For example, non-lock-free atomic operations will allow
            such a race to be observed.</p>
        </emu-note>



      <emu-note>
        <p>CLAIM: If an execution has only viable atomic operations and is conflict-free among its non-atomic operations it will appear to be sequentially consistent.</p>

        <p>NO: That's not true because of speculation and write buffering.</p>
      </emu-note>
      
	

              <p>OPEN QUESTION 1: Right now two atomic reads that conflict but don't match are flagged as not viable.  This may be too harsh.  (Note we do support the case where an atomic read conflicts with a non-atomic read.)  In a practical implementation, if the two are lock-free they'll be properly ordered PROVIDED THE HARDWARE SUPPORTS THIS.  If one is lock-free and the other not, then the lock-free access will be ordered before, between, or after the lock/unlock pair for the non-lock-free access (the lock location does not overlap the accessed location).  If both are non-lock-free, the lock will take care of ordering the accesses.</p>

        <p>I actually wonder about ARM in this regard but it's probably OK.  For 64-bit atomics we'll need to use LDREXD to load 8 bytes followed by CLREX.  A conflicting LDR or even LDREX, say, on another core does not affect this.  There are no indications that garbage would be returned anywhere for loads (stores may flip out but that's a different issue).</p>


          <p>Two accesses can be in a data race without actually conflicting.  In particular, viable atomic accesses can be in a data race if they overlap but one is executed before the other.</p>

          <p>Viable atomic operations that are in a data race can be used for synchronization.  Consider two racing atomic writes, which will be executed in some order.  If an atomic read happen after both writes have finished (in the synchronization order) and reads the memory written by the writes, then the read is ordered after the writes in the happens-before relation.  In some other execution, though, the two writes may actually conflict, and though the read may still be executed after both writes, the writes, being non-viable, will not happen-before the read.</p>

	
